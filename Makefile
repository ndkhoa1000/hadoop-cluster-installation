# --- CแบคU HรNH ---
PROJECT_DIR = /home/hadoop_n1/wordcount
JAR_FILE = $(PROJECT_DIR)/target/wordcount-1.0.jar
CLASS_NAME = com.example.WordCount
INPUT_HDFS = /input
OUTPUT_HDFS = /output

# ๐ BIแบพN QUAN TRแปNG: File input mแบทc ฤแปnh
# Dรนng dแบฅu ?= ฤแป nแบฟu bแบกn khรดng nhแบญp gรฌ, nรณ sแบฝ lแบฅy "test.txt"
# Nแบฟu bแบกn nhแบญp giรก trแป khรกc, nรณ sแบฝ lแบฅy giรก trแป bแบกn nhแบญp.
FILE ?= test.txt

# --- CรC LแปNH ---

# Chแบกy toรn bแป quy trรฌnh mแบทc ฤแปnh
all: build clean prepare run show

# 1. Build code
build:
	@echo "๐ ฤang build code..."
	mvn clean package -f $(PROJECT_DIR)/pom.xml -q

# 2. Xรณa dแปฏ liแปu cลฉ trรชn HDFS
clean:
	@echo "๐งน ฤang dแปn dแบนp HDFS..."
	-hdfs dfs -rm -r $(OUTPUT_HDFS)
	-hdfs dfs -rm -r $(INPUT_HDFS)

# 3. ฤแบฉy file bแบกn chแปn lรชn HDFS
prepare:
	@echo "๐ค ฤang xแปญ lรฝ file: $(FILE)"
	@# Kiแปm tra xem file cรณ tแปn tแบกi khรดng trฦฐแปc khi upload
	@if [ ! -f "$(FILE)" ]; then \
		echo "โ LแปI: Khรดng tรฌm thแบฅy file '$(FILE)'"; \
		exit 1; \
	fi
	hdfs dfs -mkdir -p $(INPUT_HDFS)
	hdfs dfs -put -f $(FILE) $(INPUT_HDFS)/

# 4. Chแบกy MapReduce
run:
	@echo "๐ ฤang chแบกy Hadoop..."
	hadoop jar $(JAR_FILE) $(CLASS_NAME) $(INPUT_HDFS) $(OUTPUT_HDFS)

# 5. Xem kแบฟt quแบฃ
show:
	@echo "๐ Kแบฟt quแบฃ:"
	hdfs dfs -cat $(OUTPUT_HDFS)/*